{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c9383-6d66-40d2-9a32-d55f474ebdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pysr\n",
    "import sympy\n",
    "import math\n",
    "from pysr import PySRRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1eca0-4219-4eda-9103-374e9d17511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesn't work to install torch, so I likely need to run this in the command line, though I will leave it here for reference\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172d591-5315-41c1-9bbf-91e462a780ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc01dc1-9263-4001-bb7b-162b422a0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e395c-38cd-474b-a81a-1ea692294894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sxs\n",
    "print(sxs.__file__)\n",
    "print(sxs.__version__)\n",
    "print(dir(sxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5bcc4-279f-4e1e-b29c-c67793eacf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe(non_eccentric, non_spinning, aligned_spin, not_deprecated):\n",
    "    df = sxs.load(\"dataframe\")\n",
    "    df = df.loc[np.isfinite(df[\"common_horizon_time\"])]\n",
    "    if non_eccentric:\n",
    "        df = df.loc[df['reference_eccentricity'] < 0.01]\n",
    "    if non_spinning:\n",
    "        df = df.loc[df[\"reference_dimensionless_spin1_mag\"] < 0.001]\n",
    "        df = df.loc[df[\"reference_dimensionless_spin2_mag\"] < 0.001]\n",
    "    if aligned_spin:\n",
    "        df = df.loc[df[\"reference_dimensionless_spin1_x\"] < 0.001]\n",
    "        df = df.loc[df[\"reference_dimensionless_spin2_x\"] < 0.001]\n",
    "        df = df.loc[df[\"reference_dimensionless_spin1_y\"] < 0.001]\n",
    "        df = df.loc[df[\"reference_dimensionless_spin2_y\"] < 0.001]\n",
    "    if not_deprecated:\n",
    "        df = df.loc[df[\"deprecated\"] == False]\n",
    "        df = df.drop('SXS:BBH:0621') #All of my best models were having a hard time fitting CHT for this simulation. Seems like an outlier\n",
    "    return df    \n",
    "    \n",
    "df = dataframe(non_eccentric = True, non_spinning = False, aligned_spin = False, not_deprecated = True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b4eab-c380-4b89-a033-9d604554f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here I write some code to convert the simulation parameters that Vaishak gave me into the parameters I need to predict CHT from my models\n",
    "m_1 = 0.554763952862425\n",
    "m_2 = 0.445251975007412\n",
    "q = m_1/m_2\n",
    "q_n = q/np.max(df[\"reference_mass_ratio\"])\n",
    "\n",
    "s_1 =  np.array([-0.014131739872718789, 0.17993900077887057, -0.39832502308873785])\n",
    "s_2 =  np.array([-0.4676236498668915, -0.008958494480525601, 0.5435607064742118])\n",
    "\n",
    "L = np.array([0.0008175197573002864, 0.0009421312931779968, 0.015290980276651522])\n",
    "L_mag = np.sqrt(np.dot(L, L))\n",
    "T = 2*np.pi/L_mag\n",
    "T_n = T/np.max(ref_orb_period)\n",
    "\n",
    "def chi_eff(m_1, m_2, s_1, s_2, L):\n",
    "    return (m_1*np.dot(s_1, L) + m_2*np.dot(s_2, L))/(m_1 + m_2)\n",
    "\n",
    "def chi_perp(s, L):\n",
    "    x = np.cross(s, L)\n",
    "    return np.sqrt(np.dot(x, x))\n",
    "\n",
    "X_eff = chi_eff(m_1, m_2, s_1, s_2, L)\n",
    "\n",
    "X1_perp = chi_perp(s_1, L)\n",
    "\n",
    "X2_perp = chi_perp(s_2, L)\n",
    "\n",
    "sim = np.array([[T, q, X_eff, X1_perp, X2_perp]])\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9b7fe-45d9-4190-8e5d-70ca99de85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here I write some code to convert the simulation parameters that Vaishak gave me into the parameters I need to predict CHT from my models\n",
    "m_1 = 0.554763952862425\n",
    "m_2 = 0.445251975007412\n",
    "q = m_1/m_2\n",
    "q_n = q/np.max(df[\"reference_mass_ratio\"])\n",
    "\n",
    "s_1 =  np.array([-0.014131739872718789, 0.17993900077887057, -0.39832502308873785])\n",
    "s_2 =  np.array([-0.4676236498668915, -0.008958494480525601, 0.5435607064742118])\n",
    "\n",
    "L = np.array([0.0008175197573002864, 0.0009421312931779968, 0.015290980276651522])\n",
    "L_mag = np.sqrt(np.dot(L, L))\n",
    "T = 2*np.pi/L_mag\n",
    "T_n = T/np.max(ref_orb_period)\n",
    "\n",
    "def chi_eff(m_1, m_2, s_1, s_2, L):\n",
    "    return (m_1*np.dot(s_1, L) + m_2*np.dot(s_2, L))/(L_mag*(m_1 + m_2))\n",
    "\n",
    "def chi_perp(s, L):\n",
    "    x = np.cross(s, L)\n",
    "    return np.sqrt(np.dot(x, x))\n",
    "\n",
    "X_eff = chi_eff(m_1, m_2, s_1, s_2, L)\n",
    "\n",
    "X1_perp = chi_perp(s_1, L)\n",
    "\n",
    "X2_perp = chi_perp(s_2, L)\n",
    "\n",
    "sim_nn = torch.tensor([T_n, q_n, X_eff, X1_perp, X2_perp])\n",
    "sim_nn = sim_nn.float()\n",
    "sim_sr = np.array([[T, q, X_eff, X1_perp, X2_perp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebd201-ca6e-4833-bed9-6ee2692c086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This first block subtracts corrections due to varying mass ratio from quadrupolar, Newtonian model\n",
    "init_param_q = np.array([[T, q]])\n",
    "with open(\"best_model_0.446.pk\", 'rb') as file:\n",
    "    loaded_model_q = pickle.load(file)\n",
    "\n",
    "#This second block subtracts spin corrections from quadrupolar, Newtonian model\n",
    "init_param_spin = np.array([[T, q, X_eff]])\n",
    "with open(\"chi_spin_model_0.865.pk\", 'rb') as file:\n",
    "    loaded_model_spin = pickle.load(file)\n",
    "\n",
    "#This third block subracts precession corrections from quadrupolar, Newtonian model\n",
    "init_param_prec = np.array([[T, q, X1_perp, X2_perp]])\n",
    "with open(\"chi_spin_model_0.749.pk\", 'rb') as file:\n",
    "    loaded_model_prec = pickle.load(file)\n",
    "    \n",
    "corrections = loaded_model_q.predict(init_param_q) + loaded_model_spin.predict(init_param_spin) + loaded_model_prec.predict(init_param_prec) #Compile corrections from mass ratio, spin, and precession\n",
    "\n",
    "corrected_CHT = Newtonian_CHT([T, q]) - corrections #Subtracts \"post-Newtonian\" corrects from the Newtonian predictions for CHT\n",
    "\n",
    "print(corrected_CHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148adac-ce9a-4098-b7b8-ed34da45897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_E(outputs, labels):\n",
    "   return (outputs - labels)/labels #For every simulation in a batch, I take the difference between the CHT proportion\n",
    "    #associated with that simulation and the CHT proportion predicted by my model weighted by the simulation proportion. This should give the proportion\n",
    "    #residual of my model's CHT predictions, then I sum up over the batch and divide by the size of the batch\n",
    "    \n",
    "criterion = weighted_E\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation_function):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 120)\n",
    "        self.fc2 = nn.Linear(120, 120)\n",
    "        self.fc3 = nn.Linear(120, 84)\n",
    "        self.fc4 = nn.Linear(84, 1)\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation_function(self.fc1(x))\n",
    "        x = self.activation_function(self.fc2(x))\n",
    "        x = self.activation_function(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85700ff5-64b4-4475-9f72-ac665cc89dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(nn.ReLU())\n",
    "model_path = 'nnet_33177.pth'\n",
    "\n",
    "net.load_state_dict(torch.load(model_path, weights_only=False))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42d33a-fa16-43cd-bd0d-1e9ab2d81263",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHT_pred = net(sim)\n",
    "CHT_pred = float(CHT_pred)\n",
    "print(\"Common horizon time is \" + str(round(float(CHT_pred*np.max(df[\"common_horizon_time\"] - df[\"reference_time\"])), 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
